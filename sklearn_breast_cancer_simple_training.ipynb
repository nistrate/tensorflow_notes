{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn_breast_cancer_simple_training",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxnRiCgryavQbScFwceq+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nistrate/tensorflow_notes/blob/master/sklearn_breast_cancer_simple_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tGtmdcR_6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c97cdb2c-e1c9-4f4f-b3de-3a8849d9cd04"
      },
      "source": [
        "#!pip install -q tensorflow==2.0.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr0LyndASRck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV3oLiSyUtM5",
        "colab_type": "text"
      },
      "source": [
        "Linear Classification Theory\n",
        "\n",
        "Recap the ML steps\n",
        "1) Load in the datat (x , y)\n",
        "2) Instatiate the model\n",
        "3) Train (\"fit\") the model ( model.fit(x,y) )\n",
        "4) Evaluate our model (accuracy on the train data)\n",
        "\n",
        "We are going to look at the:\n",
        "\n",
        "1) Architecture of the model (equation to go rfom input to prediction)\n",
        "2) How do we train the model\n",
        "  - cost / loss / error function function\n",
        "  - gradient descent to minimize the cost\n",
        "\n",
        "Definition of a line $y = wx+b$ (2D)\n",
        "\n",
        "$x_1$ is the horizontal axis $x$\n",
        "$x_2$ is the vertical axis $y$\n",
        "\n",
        "The equation of a line can be rewritten as:\n",
        "$$\n",
        "w_1 x_1 + w_2 x_2 + b = 0\n",
        "$$\n",
        "\n",
        " - How do we clasify?\n",
        "$$\n",
        "a = w_1 x_1 + w_2 x_2 + b\\\\\n",
        "~~~~~if~ a \\ge 0 \\rightarrow predict~1\\\\\n",
        "~~~~~if~ a < 0 \\rightarrow predict~0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_PaYTuabP3T",
        "colab_type": "text"
      },
      "source": [
        "**Basic Structure of a tf program**\n",
        "\n",
        "D = #input size\n",
        "\n",
        "X_train, y_train = #Data for training\n",
        "X_test, y_test = #Data for testing\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Input(shape = (D,)),\n",
        "                                    tf.keras.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        " #Sequential means one after another\n",
        "\n",
        "\n",
        "**training the model**\n",
        "\n",
        " model.compile(optimizer = 'adam',\n",
        "               loss = 'binary_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        " \n",
        " #optimizer is the algorith like gradient descent, adam is a common one\n",
        " #metrics accuracy = #correct / #total\n",
        "\n",
        " #fitting\n",
        "\n",
        " r = model.fit(X_train, y_train,\n",
        "               validation_data = (X_test, y_test),\n",
        "               epochs = 100)\n",
        " \n",
        " plt.plot(r.history['loss'], label = 'loss') #training\n",
        " plt.plot(r.history['val_loss'], label = 'val_loss') #test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYLKWx3rbbvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction if a patients tumor is malignant or benign\n",
        "\n",
        "#Load Data\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv6PYjmdb3Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the data\n",
        "data = load_breast_cancer() "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnpDksqab7uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c47eadfe-93ba-4ad8-ad9d-a02594bf4b1c"
      },
      "source": [
        "# check the type of data\n",
        "type(data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhzb8Qryb_oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "040a3e20-7284-4de6-9189-6d2e55acec5e"
      },
      "source": [
        "# note: this is a bunch object\n",
        "# this basically acts like a dictionary where you can treat the keys like atributes\n",
        "\n",
        "data.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-4megCQcObx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7aa3321e-5ec9-401d-f5fb-97fcf6e576ab"
      },
      "source": [
        "# 'data' (the attribute) means the input data\n",
        "data.data.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEre664RcXUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "ffd677f2-720d-4f18-8fd7-4840e8bdc5bb"
      },
      "source": [
        "# 'targets'\n",
        "data.target"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cFOATBxceDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07d70191-b523-41bb-93f5-bdf9cc34cd7a"
      },
      "source": [
        "data.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8A8FH4jcg5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34a969ce-0d79-4e38-8159-c819a258c30d"
      },
      "source": [
        "data.target.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fOZf4f5ckB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "22cf20b9-096a-4dcb-a66c-49ec66087937"
      },
      "source": [
        "data.feature_names"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjOWjOKHcl6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normally we would put all of our imports at the top\n",
        "# but this lets us tell a story\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split the data into train and test sets\n",
        "# this lets us simulate how our model will perform in the future\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size  = 0.33)\n",
        "\n",
        "N,D = X_train.shape"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvSzTuSVdX_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data\n",
        "# you'll learn why scaling is needed in a later course (the main idea is that you want to normalize everything so it operates in the same numerical range) x = (x-\\mu) / sigma\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZqTKY4rdYr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5ada2ff-6501-405b-f669-53400859dc61"
      },
      "source": [
        "# Now all the TensorFlow stuff\n",
        "# We start with building a model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Input(shape = (D,)),\n",
        "                                    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "# Alternatively, we can do:\n",
        "#model = tf.keras.models.Sequential()\n",
        "#model.add(tf.keras.layers.Dense(1, input_shape = (D,), activation = 'sigmoid))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "r = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100 )\n",
        "\n",
        "# Evaluating the model - evaluate() returns loss and accuracy\n",
        "print ('Train score: ', model.evaluate(X_train, y_train))\n",
        "print ('Test score: ', model.evaluate(X_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f0053ae9840> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Bad argument number for Name: 4, expecting 3\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f0053ae9840> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Bad argument number for Name: 4, expecting 3\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4484 - accuracy: 0.9062WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f00536578c8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Bad argument number for Name: 4, expecting 3\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f00536578c8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Bad argument number for Name: 4, expecting 3\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5139 - accuracy: 0.7585 - val_loss: 0.4347 - val_accuracy: 0.8138\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7979 - val_loss: 0.3927 - val_accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8215 - val_loss: 0.3586 - val_accuracy: 0.8830\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8556 - val_loss: 0.3304 - val_accuracy: 0.9043\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8819 - val_loss: 0.3063 - val_accuracy: 0.9149\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8950 - val_loss: 0.2869 - val_accuracy: 0.9202\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.9081 - val_loss: 0.2707 - val_accuracy: 0.9255\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2993 - accuracy: 0.9186 - val_loss: 0.2565 - val_accuracy: 0.9255\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2834 - accuracy: 0.9344 - val_loss: 0.2447 - val_accuracy: 0.9309\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.9475 - val_loss: 0.2337 - val_accuracy: 0.9362\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9501 - val_loss: 0.2247 - val_accuracy: 0.9362\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.9528 - val_loss: 0.2164 - val_accuracy: 0.9415\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.9528 - val_loss: 0.2091 - val_accuracy: 0.9415\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2270 - accuracy: 0.9528 - val_loss: 0.2023 - val_accuracy: 0.9415\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.9528 - val_loss: 0.1963 - val_accuracy: 0.9415\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9554 - val_loss: 0.1909 - val_accuracy: 0.9415\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9580 - val_loss: 0.1858 - val_accuracy: 0.9468\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9606 - val_loss: 0.1811 - val_accuracy: 0.9468\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1919 - accuracy: 0.9633 - val_loss: 0.1770 - val_accuracy: 0.9521\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9633 - val_loss: 0.1732 - val_accuracy: 0.9521\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1814 - accuracy: 0.9606 - val_loss: 0.1694 - val_accuracy: 0.9574\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1765 - accuracy: 0.9606 - val_loss: 0.1661 - val_accuracy: 0.9574\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9606 - val_loss: 0.1628 - val_accuracy: 0.9574\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9606 - val_loss: 0.1600 - val_accuracy: 0.9574\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.9633 - val_loss: 0.1574 - val_accuracy: 0.9574\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9659 - val_loss: 0.1548 - val_accuracy: 0.9574\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1571 - accuracy: 0.9659 - val_loss: 0.1522 - val_accuracy: 0.9574\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9659 - val_loss: 0.1500 - val_accuracy: 0.9574\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.9659 - val_loss: 0.1479 - val_accuracy: 0.9574\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9659 - val_loss: 0.1458 - val_accuracy: 0.9574\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9659 - val_loss: 0.1440 - val_accuracy: 0.9574\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9659 - val_loss: 0.1422 - val_accuracy: 0.9574\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9659 - val_loss: 0.1404 - val_accuracy: 0.9574\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9659 - val_loss: 0.1385 - val_accuracy: 0.9574\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9659 - val_loss: 0.1370 - val_accuracy: 0.9574\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9659 - val_loss: 0.1355 - val_accuracy: 0.9574\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9659 - val_loss: 0.1341 - val_accuracy: 0.9574\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.9659 - val_loss: 0.1328 - val_accuracy: 0.9574\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1278 - accuracy: 0.9685 - val_loss: 0.1315 - val_accuracy: 0.9628\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9685 - val_loss: 0.1301 - val_accuracy: 0.9628\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9685 - val_loss: 0.1290 - val_accuracy: 0.9628\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9685 - val_loss: 0.1278 - val_accuracy: 0.9628\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9685 - val_loss: 0.1267 - val_accuracy: 0.9628\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9685 - val_loss: 0.1257 - val_accuracy: 0.9628\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9685 - val_loss: 0.1246 - val_accuracy: 0.9574\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9685 - val_loss: 0.1237 - val_accuracy: 0.9574\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9685 - val_loss: 0.1226 - val_accuracy: 0.9574\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9685 - val_loss: 0.1217 - val_accuracy: 0.9574\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9711 - val_loss: 0.1209 - val_accuracy: 0.9574\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9711 - val_loss: 0.1200 - val_accuracy: 0.9574\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9711 - val_loss: 0.1191 - val_accuracy: 0.9574\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9711 - val_loss: 0.1183 - val_accuracy: 0.9574\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1086 - accuracy: 0.9711 - val_loss: 0.1176 - val_accuracy: 0.9521\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1076 - accuracy: 0.9711 - val_loss: 0.1168 - val_accuracy: 0.9521\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1066 - accuracy: 0.9711 - val_loss: 0.1161 - val_accuracy: 0.9521\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9711 - val_loss: 0.1153 - val_accuracy: 0.9521\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9711 - val_loss: 0.1146 - val_accuracy: 0.9521\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9711 - val_loss: 0.1140 - val_accuracy: 0.9521\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9711 - val_loss: 0.1134 - val_accuracy: 0.9521\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9711 - val_loss: 0.1128 - val_accuracy: 0.9521\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9711 - val_loss: 0.1121 - val_accuracy: 0.9521\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9711 - val_loss: 0.1116 - val_accuracy: 0.9521\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9711 - val_loss: 0.1109 - val_accuracy: 0.9521\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9711 - val_loss: 0.1104 - val_accuracy: 0.9521\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9711 - val_loss: 0.1099 - val_accuracy: 0.9521\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9711 - val_loss: 0.1094 - val_accuracy: 0.9521\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9711 - val_loss: 0.1088 - val_accuracy: 0.9521\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9711 - val_loss: 0.1083 - val_accuracy: 0.9521\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9711 - val_loss: 0.1078 - val_accuracy: 0.9521\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9711 - val_loss: 0.1074 - val_accuracy: 0.9521\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9711 - val_loss: 0.1069 - val_accuracy: 0.9521\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9711 - val_loss: 0.1064 - val_accuracy: 0.9521\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9711 - val_loss: 0.1060 - val_accuracy: 0.9521\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9711 - val_loss: 0.1056 - val_accuracy: 0.9521\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.9711 - val_loss: 0.1052 - val_accuracy: 0.9521\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9711 - val_loss: 0.1047 - val_accuracy: 0.9521\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9711 - val_loss: 0.1042 - val_accuracy: 0.9521\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9711 - val_loss: 0.1039 - val_accuracy: 0.9521\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9711 - val_loss: 0.1035 - val_accuracy: 0.9521\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9711 - val_loss: 0.1032 - val_accuracy: 0.9521\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9738 - val_loss: 0.1028 - val_accuracy: 0.9521\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9738 - val_loss: 0.1024 - val_accuracy: 0.9521\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9738 - val_loss: 0.1021 - val_accuracy: 0.9521\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9738 - val_loss: 0.1018 - val_accuracy: 0.9521\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9738 - val_loss: 0.1014 - val_accuracy: 0.9521\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9738 - val_loss: 0.1011 - val_accuracy: 0.9521\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9738 - val_loss: 0.1007 - val_accuracy: 0.9521\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9764 - val_loss: 0.1004 - val_accuracy: 0.9521\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9764 - val_loss: 0.1001 - val_accuracy: 0.9521\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9764 - val_loss: 0.0998 - val_accuracy: 0.9521\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9764 - val_loss: 0.0995 - val_accuracy: 0.9521\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9764 - val_loss: 0.0992 - val_accuracy: 0.9521\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9764 - val_loss: 0.0989 - val_accuracy: 0.9521\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9764 - val_loss: 0.0986 - val_accuracy: 0.9521\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9764 - val_loss: 0.0983 - val_accuracy: 0.9521\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9790 - val_loss: 0.0981 - val_accuracy: 0.9521\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9790 - val_loss: 0.0978 - val_accuracy: 0.9521\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9816 - val_loss: 0.0975 - val_accuracy: 0.9574\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9843 - val_loss: 0.0973 - val_accuracy: 0.9574\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9843 - val_loss: 0.0970 - val_accuracy: 0.9574\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9843\n",
            "Train score:  [0.08034517616033554, 0.9842519760131836]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9574\n",
            "Test score:  [0.09697522222995758, 0.957446813583374]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEt44Qs1eqEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c401a0e7-d055-4acd-e53b-9045fcaa2e81"
      },
      "source": [
        "# Plot what's returned by model.fit()\n",
        "\n",
        "plt.plot(r.history['loss'], label = 'loss')\n",
        "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0052a17198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3cEma6JgXUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "50e485ce-d086-4df1-9896-0bd7df73550a"
      },
      "source": [
        "# Plot accuracy\n",
        "\n",
        "plt.plot(r.history['accuracy'], label = 'accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label = 'val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f005436e390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U1L5ctEIyVI",
        "colab_type": "text"
      },
      "source": [
        "Part:2 Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lzWecNWg1ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76634e75-0c9c-4664-e986-b828a4f0f94e"
      },
      "source": [
        "# Make Prediction\n",
        "\n",
        "P = model.predict(X_test)\n",
        "\n",
        "print(P) # they are output of a sigmoid, interpreted as probabilities P(y=1|x)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f00535572f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Bad argument number for Name: 4, expecting 3\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f00535572f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Bad argument number for Name: 4, expecting 3\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "[[9.8606479e-01]\n",
            " [4.1553378e-04]\n",
            " [9.6783161e-01]\n",
            " [4.8014820e-03]\n",
            " [2.4719320e-05]\n",
            " [8.3928209e-15]\n",
            " [9.6384680e-01]\n",
            " [1.2734532e-04]\n",
            " [9.8675942e-01]\n",
            " [2.9632151e-02]\n",
            " [9.6661973e-01]\n",
            " [9.9409521e-01]\n",
            " [3.5687476e-02]\n",
            " [2.7757883e-04]\n",
            " [9.9990493e-01]\n",
            " [9.9194896e-01]\n",
            " [3.2919715e-07]\n",
            " [7.6711899e-01]\n",
            " [2.8780401e-03]\n",
            " [9.9959242e-01]\n",
            " [9.4518757e-01]\n",
            " [1.4226094e-01]\n",
            " [9.9976742e-01]\n",
            " [9.6625912e-01]\n",
            " [9.6164656e-01]\n",
            " [6.8942887e-01]\n",
            " [5.0482551e-09]\n",
            " [3.5041571e-04]\n",
            " [8.0497897e-01]\n",
            " [9.9731517e-01]\n",
            " [3.5044894e-07]\n",
            " [3.3253431e-04]\n",
            " [5.3880006e-02]\n",
            " [2.3456103e-06]\n",
            " [9.3770683e-01]\n",
            " [5.3767830e-01]\n",
            " [9.9907702e-01]\n",
            " [9.9704444e-01]\n",
            " [2.9709997e-06]\n",
            " [4.9753177e-01]\n",
            " [4.4691677e-07]\n",
            " [7.0002137e-10]\n",
            " [9.9818480e-01]\n",
            " [6.9280034e-01]\n",
            " [4.3046474e-04]\n",
            " [9.9620163e-01]\n",
            " [9.9503428e-01]\n",
            " [5.8381021e-02]\n",
            " [2.7182698e-04]\n",
            " [5.6565547e-01]\n",
            " [9.9641800e-01]\n",
            " [9.9757820e-01]\n",
            " [9.7890395e-01]\n",
            " [2.9774308e-03]\n",
            " [1.5297897e-05]\n",
            " [9.9170685e-01]\n",
            " [6.1204135e-03]\n",
            " [4.2644143e-04]\n",
            " [9.8776597e-01]\n",
            " [1.3008714e-04]\n",
            " [9.9880940e-01]\n",
            " [9.4912612e-01]\n",
            " [9.8367500e-01]\n",
            " [9.4483674e-01]\n",
            " [4.9933791e-04]\n",
            " [9.4814456e-01]\n",
            " [8.0155776e-05]\n",
            " [8.9426637e-01]\n",
            " [9.9852800e-01]\n",
            " [9.1584492e-01]\n",
            " [9.9813074e-01]\n",
            " [9.9911362e-01]\n",
            " [1.3042390e-03]\n",
            " [1.1852682e-03]\n",
            " [9.8650908e-01]\n",
            " [8.7886852e-01]\n",
            " [9.9996209e-01]\n",
            " [8.8836658e-01]\n",
            " [4.2784423e-02]\n",
            " [9.8748374e-01]\n",
            " [9.9514222e-01]\n",
            " [9.9949878e-01]\n",
            " [4.2443731e-05]\n",
            " [9.9996519e-01]\n",
            " [9.8355275e-01]\n",
            " [9.9719512e-01]\n",
            " [7.2199404e-03]\n",
            " [9.6030211e-01]\n",
            " [1.0228632e-04]\n",
            " [5.2574307e-01]\n",
            " [8.9358628e-01]\n",
            " [8.3803189e-01]\n",
            " [2.7076006e-02]\n",
            " [9.9333537e-01]\n",
            " [6.5794215e-05]\n",
            " [6.8142724e-01]\n",
            " [9.8487294e-01]\n",
            " [9.9960661e-01]\n",
            " [9.9580908e-01]\n",
            " [3.7510666e-01]\n",
            " [9.9923742e-01]\n",
            " [3.3864982e-09]\n",
            " [9.9390626e-01]\n",
            " [9.9360669e-01]\n",
            " [9.4708359e-01]\n",
            " [9.9880010e-01]\n",
            " [9.9934995e-01]\n",
            " [9.9962789e-01]\n",
            " [9.7694945e-01]\n",
            " [1.9212067e-03]\n",
            " [7.7638352e-01]\n",
            " [7.9137087e-04]\n",
            " [6.0424674e-01]\n",
            " [8.7270558e-01]\n",
            " [9.9654138e-01]\n",
            " [1.8289596e-02]\n",
            " [4.1363882e-07]\n",
            " [2.3159426e-01]\n",
            " [9.7061980e-01]\n",
            " [9.8943299e-01]\n",
            " [9.9967033e-01]\n",
            " [9.8372388e-01]\n",
            " [9.9756068e-01]\n",
            " [9.9863195e-01]\n",
            " [7.6676810e-01]\n",
            " [2.6382446e-01]\n",
            " [9.4768173e-01]\n",
            " [1.5166402e-03]\n",
            " [9.6287680e-01]\n",
            " [9.9079078e-01]\n",
            " [9.8780245e-01]\n",
            " [3.3854604e-01]\n",
            " [3.3547282e-03]\n",
            " [9.0495712e-01]\n",
            " [5.1627934e-01]\n",
            " [8.5579622e-01]\n",
            " [3.3501074e-05]\n",
            " [4.7451751e-05]\n",
            " [1.8354356e-03]\n",
            " [9.9960315e-01]\n",
            " [2.9812932e-02]\n",
            " [6.2169760e-02]\n",
            " [9.9992496e-01]\n",
            " [1.8978211e-05]\n",
            " [9.8502791e-01]\n",
            " [2.6463456e-06]\n",
            " [9.9216390e-01]\n",
            " [7.8090763e-01]\n",
            " [9.9529612e-01]\n",
            " [5.3565478e-01]\n",
            " [5.9391856e-03]\n",
            " [2.2045106e-02]\n",
            " [9.9351352e-01]\n",
            " [9.6213448e-01]\n",
            " [9.9407274e-01]\n",
            " [9.9700284e-01]\n",
            " [9.6446347e-01]\n",
            " [6.3435082e-06]\n",
            " [6.8157744e-01]\n",
            " [9.0939617e-01]\n",
            " [9.9211001e-01]\n",
            " [3.7811687e-06]\n",
            " [9.9773175e-01]\n",
            " [1.9013882e-04]\n",
            " [9.9905622e-01]\n",
            " [9.9091923e-01]\n",
            " [9.9742800e-01]\n",
            " [2.2723377e-03]\n",
            " [8.8710845e-01]\n",
            " [9.9868941e-01]\n",
            " [3.4427643e-04]\n",
            " [6.6907120e-01]\n",
            " [9.9878502e-01]\n",
            " [9.8089600e-01]\n",
            " [4.8744202e-02]\n",
            " [3.4157693e-02]\n",
            " [1.2793839e-02]\n",
            " [4.1947541e-01]\n",
            " [1.2332976e-01]\n",
            " [9.8988283e-01]\n",
            " [9.9973404e-01]\n",
            " [1.3977103e-05]\n",
            " [9.9689484e-01]\n",
            " [9.9655092e-01]\n",
            " [2.4498519e-04]\n",
            " [4.6777754e-04]\n",
            " [9.9689096e-01]\n",
            " [8.7639654e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHjlYtzFJDl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bf6c3437-a702-4015-bd15-91d9e9aa21ae"
      },
      "source": [
        "# round to get the actual predictions\n",
        "# Note: has to be flattened since the targets are size (N,) while the predictions are size (N,1)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "P = np.round(P).flatten()\n",
        "print(P)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZKqwHhjKnED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c0a3e748-c59c-46b3-9d55-f9c005f5a2ca"
      },
      "source": [
        "#Calculate the accuracy, compare it to evaluate() output\n",
        "\n",
        "print('Mannually calculated accuracy:' , np.mean(P == y_test))\n",
        "print('Evaluate output: ', model.evaluate(X_test, y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mannually calculated accuracy: 0.9574468085106383\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9574\n",
            "Evaluate output:  [0.09697522222995758, 0.957446813583374]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bujb1IofLDSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}