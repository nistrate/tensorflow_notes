{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artificial Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYQrz1+kQiR27uFrfMKpMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nistrate/tensorflow_notes/blob/master/Artificial_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1w7NW3yEFm",
        "colab_type": "text"
      },
      "source": [
        "This section will introduce thw concept of a *feed forward neural network*.\n",
        "\n",
        "Such a network is the basisi for other kinds of more complex networks such as\n",
        "- Convolutional Neural Networks (CNNs)\n",
        "- Recurrent Neural Networks (RNNs)\n",
        "\n",
        "We are trying to createa neural network in a computer. The name derives from the brain neurons. An artificial neural network is trying to simulate a working brain, or more precise a collection of neurons with their chemical and electrical connectivity.\n",
        "\n",
        "A feed forward network is formed of multiple interconnected layers of neurons. The input is fed in the first layer, while the output comes out of the last layer.\n",
        "\n",
        "Section outline:\n",
        "- Model Architecture.\n",
        "  - How does a feedforward neural network work?\n",
        "  - What is its ``equation\"?\n",
        "- The geometric picture.\n",
        "  - How does this relate back to the ``machine learning is nothing but a geometry problem''?\n",
        "- Activation functions.\n",
        "  - These are what make neural network more powerful.\n",
        "- Multiclass clasification.\n",
        "  - Previously only discussed binary classifications (dog/cat, fraud/no fraud, pruchase/leave).\n",
        "- Image data\n",
        "  - Deep learning excels at images, text, and sound.\n",
        "  - How does this relate to ``all data is the same\"?\n",
        "- Image classification notebook; Regression notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvA43V4EmsaC",
        "colab_type": "text"
      },
      "source": [
        "Forward Propagation\n",
        "\n",
        "Consider a dense network of Input $\\rightarrow$ Layer One $\\rightarrow$ Ouput\n",
        "\n",
        "The connection between the input to a node in Layer 1 is logistic regression and represents a neuron. Each neuron may be calculationg something different, given a different set of weights.\n",
        "\n",
        "E.g. input is a face. One neuron looks for the presence of a an eye, another looks for the presence of a nose. We say that each neuron is looking for a certain feature.\n",
        "\n",
        "1) The same input can be fed to multiple diffferent neurons, each calculating somethiong different (more neurons per layer).\n",
        "\n",
        "2) Neurons in one layer ca act as inputs to another layer.\n",
        "\n",
        "Lines $\\rightarrow$ Neurons\n",
        "\n",
        " - a line $ ax+b $\n",
        " - a neuron $\\sigma(w^{T}x+b)$\n",
        "\n",
        "The natural question arrises: What should we do if we have more than one neuron per layer?\n",
        "\n",
        "- call the output of the $j$th neuron - $z_j$\n",
        "- say there are $M$ neurons, so $j=1,2 ,...,M$\n",
        "\n",
        "$$\n",
        "z_j = \\sigma(w_j^T x + b_j) ~~~for~~~ j = 1,2,..., M \n",
        "$$\n",
        "or more compactly\n",
        "$$\n",
        "z = \\sigma(W^T x + b)\n",
        "$$\n",
        "where\n",
        "- $z$ is a vector of size $M \\times 1$\n",
        "- $x$ is a vector of size $D \\times 1$\n",
        "- $W$ is a matrix of size $D \\times M$\n",
        "- $b$ is a vector of size $M \\times 1$\n",
        "- $\\sigma()$ is an element wise operation\n",
        "\n",
        "thus \n",
        "\n",
        "$$\n",
        "p(y=1|x) = \\sigma(W^{(L)~T~}z^{(L-1)} + b^{(L)})\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obMUH6Hjn6Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}